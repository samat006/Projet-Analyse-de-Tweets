
# Analyse de Tweets avec PySpark

![Python](https://img.shields.io/badge/Python-3.10-blue)
![Spark](https://img.shields.io/badge/Spark-PySpark-orange)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13-blueviolet)

Projet d'analyse de tweets utilisant **PySpark** pour le traitement de texte et PostgreSQL pour le stockage des donnÃ©es nettoyÃ©es.

---

## ğŸ“¦ FonctionnalitÃ©s

* Lecture de tweets depuis un fichier CSV
* Nettoyage des textes (`text_clean`) : suppression des caractÃ¨res spÃ©ciaux, mise en minuscules
* Tokenization en mots (`words`)
* Vectorisation avec `CountVectorizer` (`features`)
* Encodage des labels (`label`)
* Ã‰criture des donnÃ©es nettoyÃ©es dans PostgreSQL (`tweets_clean`)

---

## ğŸ› ï¸ Technologies utilisÃ©es

* Python 3.10
* Apache Spark / PySpark
* Spark ML (`Tokenizer`, `CountVectorizer`, `StringIndexer`)
* PostgreSQL
* Nettoyage et prÃ©traitement de texte

---

## âš™ï¸ Installation et exÃ©cution

1. Cloner le dÃ©pÃ´t :

```bash
git clone https://github.com/<ton-utilisateur>/<nom-du-repo>.git
cd <nom-du-repo>
```

2. Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```

3. Lancer le script principal :

```bash
python main.py
```

Les donnÃ©es seront nettoyÃ©es et insÃ©rÃ©es dans PostgreSQL.

---

## ğŸ“ Structure du projet

```
/projet-tweets
â”‚
â”œâ”€ data/             # fichiers CSV
â”œâ”€ scripts/          # scripts PySpark
â”œâ”€ notebooks/        # notebooks Jupyter
â”œâ”€ README.md
â””â”€ requirements.txt  # dÃ©pendances Python
```

---

## ğŸ’¡ Remarques

* Les colonnes `Vector` (features) ne peuvent pas Ãªtre directement stockÃ©es dans PostgreSQL.
* Pour conserver les vecteurs, utilisez des formats comme **Parquet** ou **Pickle**.

